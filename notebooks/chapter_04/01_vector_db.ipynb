{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfa656c",
   "metadata": {},
   "source": [
    "## Vector Databases: The Heart of Semantic Search\n",
    "\n",
    "Once we have embeddings for our data—be it recipe chunks, medical documents, or product descriptions—the next question is: **where do we store them?** Storing embeddings in a plain list or a traditional database works for very small datasets, but as soon as you have thousands or millions of high-dimensional vectors, querying efficiently becomes a challenge. This is where **vector databases** come in.\n",
    "\n",
    "---\n",
    "\n",
    "### What is a Vector Database?\n",
    "\n",
    "A **vector database** is a specialized database designed to store embeddings (vectors) and perform **similarity search** efficiently. Instead of looking for exact matches like a traditional SQL database, a vector database answers questions like:\n",
    "\n",
    "- “Which chunks of text are semantically closest to this query?”  \n",
    "- “Which recipes are most similar to a chocolate cake?”  \n",
    "- “Which product descriptions match a user’s intent?”\n",
    "\n",
    "It essentially transforms your problem from keyword search to **semantic search**, where meaning, not exact wording, determines similarity.\n",
    "\n",
    "---\n",
    "\n",
    "### How it Works\n",
    "\n",
    "1. **Storing embeddings**: Each data chunk is converted into a fixed-length vector (embedding) and stored in the database along with a reference to the original text.  \n",
    "2. **Indexing**: Vector databases build efficient indexes to speed up nearest neighbor search. Common techniques include:\n",
    "   - **FAISS** (Facebook AI Similarity Search): highly optimized for CPU/GPU, supports millions of vectors.  \n",
    "   - **HNSW** (Hierarchical Navigable Small World graphs): fast approximate search, good for real-time queries.  \n",
    "3. **Querying**: When a query embedding is generated (from a user question, for example), the database computes distances (cosine similarity, Euclidean, etc.) between the query and stored vectors, returning the most similar entries.\n",
    "\n",
    "---\n",
    "\n",
    "### Benefits of Using a Vector Database\n",
    "\n",
    "- **Speed**: Can handle millions of embeddings and return results in milliseconds.  \n",
    "- **Scalability**: Designed to scale horizontally, supporting large datasets efficiently.  \n",
    "- **Semantic search**: Retrieves results based on meaning rather than exact text match.  \n",
    "- **Integration with RAG**: Perfect for retrieval-augmented generation pipelines, where relevant chunks need to be fetched for an LLM.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Use Case: Recipe PDFs\n",
    "\n",
    "Imagine you have a PDF cookbook that has been cleaned and chunked into 1,000 recipe sections.  \n",
    "\n",
    "1. You generate embeddings for each chunk using `all-mpnet-base-v2`.  \n",
    "2. You store these embeddings in a vector database like **FAISS**.  \n",
    "3. When a user queries, *“Show me chocolate dessert recipes under 30 minutes”*, the system:  \n",
    "   - Converts the query into an embedding.  \n",
    "   - Searches the vector database for closest embeddings.  \n",
    "   - Returns the corresponding recipe chunks.\n",
    "\n",
    "This allows **semantic search** that understands intent, not just keywords. For example, it could retrieve *“Quick cocoa mug cake”* even though the query didn’t literally say “mug cake.”\n",
    "\n",
    "---\n",
    "\n",
    "### Popular Open-Source Vector Databases\n",
    "\n",
    "**FAISS**, **Milvus**,  **Weaviate** , **Chroma**    \n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- A **vector database** is the backbone of any semantic search or retrieval system.  \n",
    "- It allows you to store, index, and search high-dimensional embeddings efficiently.  \n",
    "- For tasks like **recipe search, document QA, or recommendation systems**, vector databases transform raw embeddings into actionable insights.  \n",
    "\n",
    "> In short, embeddings give your data a “language” a machine can understand, and vector databases give that machine a “library” where it can find the right answers quickly.\n",
    "\n",
    "\n",
    "#### Note:\n",
    "I will stick to FAISS for this course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8654a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 chunks\n",
      "Chunk text: Directions Step 1 Preheat oven to 350 degrees F (175 degrees C). Grease and fl our two 9 inch, round, cake pans; cover bottoms with waxed paper. Step 2 In a large bowl, combine fl our, 2 cups sugar, c...\n",
      "Embedding vector (first 10 values): [-0.006904602516442537, 0.001459900289773941, -0.04020014405250549, 0.009997756220400333, 0.057940173894166946, -0.05789573863148689, 0.057525020092725754, 0.01736609824001789, -0.0022118366323411465, -0.017856286838650703]  ...\n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import warnings\n",
    "from langchain.schema import Document\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from common.helper import read_pdf, extract_recipes_from_pdf\n",
    "\n",
    "inp_dir = os.path.join(project_root, \"data\", \"chunks\")\n",
    "MODEL_NAME = \"intfloat/e5-base-v2\"\n",
    "vec_store_path = os.path.join(project_root, \"data\", \"vector_store\", \"faiss_index\")\n",
    "\n",
    "# load the embedding model  \n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=MODEL_NAME, encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "chunks = json.load(open(f\"{inp_dir}/recipe_chunks.json\", \"r\", encoding=\"utf-8\"))\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# embed one chunk for example\n",
    "chunk_text = chunks[0]['content']\n",
    "chunk_embeddings = embeddings.embed_documents([chunk_text])\n",
    "\n",
    "print(f\"Chunk text: {chunk_text[:200]}...\")\n",
    "print(f\"Embedding vector (first 10 values): {chunk_embeddings[0][:10]}  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6100a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a chunk and its metadata\n",
    "# convert to a list of Document objects to be compatible with langchain\n",
    "# create the vector store and save it locally\n",
    "\n",
    "documents = []\n",
    "for chunk in chunks:\n",
    "    documents.append(Document(page_content=chunk[\"name\"] + \" \" + chunk['content'], metadata={\"page_num\": chunk['metadata']['page'], \"name\": chunk['name']}))\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embeddings)\n",
    "vector_store.save_local(vec_store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fbc132",
   "metadata": {},
   "source": [
    "With the vector store in place, we are now ready to explore retrieval. This is the stage where we leverage the embeddings and the vector database to find the most relevant chunks for a given query. Instead of relying on exact keyword matches, retrieval uses semantic similarity — finding chunks whose meaning is closest to the user’s input. For example, if a user queries “quick chocolate desserts”, the system will return recipe chunks related to chocolate cakes, brownies, or mug cakes, even if the text doesn’t contain the exact words “quick” or “dessert”. This ability to retrieve information based on meaning rather than literal matches is the foundation of Retrieval-Augmented Generation (RAG) systems and sets the stage for building intelligent, context-aware applications on top of our recipe embeddings.\n",
    "\n",
    "Below are some query examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9393b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results for the query: 'Give me recipe of banana cake'\n",
      "\n",
      "Result 1:\n",
      "Content:  BANANA CAKE Directions Step 1 Heat oven to 180C/160C fan/gas 4. Step 2 Butter your tin and line the base and sides with baking parchment. Step 3 Mix the butter and sugar until light and fluffy, then slowly add the eggs with a little flour. Fold in the remaining flour, baking powder and bananas. Ste...\n",
      "Metadata: {'page_num': 35, 'name': ' BANANA CAKE'}\n",
      "\n",
      "Result 2:\n",
      "Content:  APPLE AND ALMOND DESSERT CAKE Directions Step 1 Preheat the oven to 170 C . Brush around the base of your tin with melted butter to grease. Line base and side with baking parchment. Step 2 Beat butter, caster sugar & vanilla in a bowl for 8 mins or till pale and creamy (by hand or electric beater)....\n",
      "Metadata: {'page_num': 37, 'name': ' APPLE AND ALMOND DESSERT CAKE'}\n",
      "\n",
      "Result 3:\n",
      "Content:  BLACK FOREST CAKE WITH CREAM FILLING AND CHERRIES Directions Step 1 Preheat oven to 350 degrees F (175 degrees C). Grease and fl our two 9 inch, round, cake pans; cover bottoms with waxed paper. Step 2 In a large bowl, combine fl our, 2 cups sugar, cocoa, baking powder, baking soda, and salt. Add e...\n",
      "Metadata: {'page_num': 13, 'name': ' BLACK FOREST CAKE WITH CREAM FILLING AND CHERRIES'}\n"
     ]
    }
   ],
   "source": [
    "# Load FAISS index\n",
    "vectorstore = FAISS.load_local(vec_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "def search_vector_db(query, k=3):\n",
    "    results = vectorstore.similarity_search(query, k=k)\n",
    "    return results\n",
    "\n",
    "# Example search\n",
    "query = \"Give me recipe of banana cake\"\n",
    "results = search_vector_db(query)\n",
    "print(f\"Top {len(results)} results for the query: '{query}'\")\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Content: {res.page_content[:300]}...\")\n",
    "    print(f\"Metadata: {res.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64fc1c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 results for the query: 'Give me cake recipe with chocolate and frosting'\n",
      "\n",
      "Result 1:\n",
      "Content:  CHOCOLATE CAKE WITH CHOCOLATE BUTTERCREAM FROSTING Directions Step 1 Preheat oven to 350º F. Prepare two 9-inch cake pans by spraying with baking spray or buttering and lightly fl ouring. Step 2 Add fl our, sugar, cocoa, baking powder, baking soda, salt and espresso powder to a large bowl or the bo...\n",
      "Metadata: {'page_num': 45, 'name': ' CHOCOLATE CAKE WITH CHOCOLATE BUTTERCREAM FROSTING'}\n",
      "\n",
      "Result 2:\n",
      "Content:  RED VELVET WITH CREAM CHEESE FROSTING Directions Step 1 Preheat oven to 350 degrees F (175 degrees C). Grease two 9-inch round pans. Step 2 Beat Butter and sugar until very light and fluffy. Add eggs and beat well. Step 3 Make a paste of cocoa and red food coloring; add to creamed mixture. Step 4 M...\n",
      "Metadata: {'page_num': 23, 'name': ' RED VELVET WITH CREAM CHEESE FROSTING'}\n",
      "\n",
      "Result 3:\n",
      "Content:  BLACK FOREST CAKE WITH CREAM FILLING AND CHERRIES Directions Step 1 Preheat oven to 350 degrees F (175 degrees C). Grease and fl our two 9 inch, round, cake pans; cover bottoms with waxed paper. Step 2 In a large bowl, combine fl our, 2 cups sugar, cocoa, baking powder, baking soda, and salt. Add e...\n",
      "Metadata: {'page_num': 13, 'name': ' BLACK FOREST CAKE WITH CREAM FILLING AND CHERRIES'}\n"
     ]
    }
   ],
   "source": [
    "# Example search\n",
    "query = \"Give me cake recipe with chocolate and frosting\"\n",
    "results = search_vector_db(query)\n",
    "print(f\"Top {len(results)} results for the query: '{query}'\")\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Content: {res.page_content[:300]}...\")\n",
    "    print(f\"Metadata: {res.metadata}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
