{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3790ac7f",
   "metadata": {},
   "source": [
    "### Semantic Chunking  \n",
    "\n",
    "Imagine you’re reading a dessert recipe. Fixed-size chunking would chop the text into equal blocks, like cutting a cake with a ruler — sometimes you get the whole \"Add sugar and butter…\" step in one chunk, and sometimes you just get \"… for 10 minutes\" dangling in the next. Not very helpful.  \n",
    "\n",
    "Semantic chunking is more like cutting a layered cake along the frosting lines — you keep the steps and ideas intact. That way, \"Mix flour, sugar, and eggs\" stays together as one meaningful unit, instead of being split in the middle.  \n",
    "\n",
    "In short:  \n",
    "- **Fixed-size chunks**: Equal slices, context may get lost.  \n",
    "- **Semantic chunks**: Natural breaks, meaning preserved.  \n",
    "\n",
    "When working with recipes (or any domain text), semantic chunking ensures each instruction or paragraph stands on its own, making it easier for retrieval and for the model to understand.  \n",
    "\n",
    "For this exercise, I have created a separate chunk for each recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c4cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "from common.helper import read_pdf, is_numeric, semantic_cunks_unsorted\n",
    "\n",
    "pdf_path = os.path.join(project_root, \"data\", \"input\", \"recipe-book.pdf\")\n",
    "out_dir = os.path.join(project_root, \"data\", \"chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7752d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the PDF file containing recipes.\n",
    "#Skip the first 10 pages (these do not contain recipes).\n",
    "#Perform semantic chunking on the remaining pages to extract recipe chunks.\n",
    "#Save the resulting chunks to a JSON file for later use.\n",
    "\n",
    "doc = read_pdf(pdf_path)\n",
    "\n",
    "skip_pages = 10   # skip initial 10 pages which do not have recipes\n",
    "\n",
    "unsorted_spans_chunks = semantic_cunks_unsorted(doc, skip_pages=skip_pages)\n",
    "with open(f\"{out_dir}/chunks_fitz.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unsorted_spans_chunks, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
