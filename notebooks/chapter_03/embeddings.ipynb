{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce7ac6b",
   "metadata": {},
   "source": [
    "## From Recipes to Embeddings: Cooking with Vectors\n",
    "\n",
    "Once the recipes are cleaned and chunked, we reach one of the most exciting stages in our journey — **embeddings**. If chunking is about breaking down messy text into digestible bites, embeddings are about giving those bites a *flavor profile* that machines can actually understand.  \n",
    "\n",
    "Think about our recipe PDF. After the preprocessing work — dealing with two-column layouts, filtering out non-recipe pages, and parsing tricky measurement tables — we’re left with logical text chunks: recipe titles, ingredient lists, step-by-step instructions, and maybe even some nutritional tables. Each of these chunks is still just plain text. To us humans, words like *“sugar”*, *“milk”*, or *“bake at 350°F”* carry meaning instantly. But for a computer, these are just strings of characters unless we find a way to represent them in a mathematical space.  \n",
    "\n",
    "That’s where embeddings come in.  \n",
    "\n",
    "---\n",
    "\n",
    "### What are Embeddings?\n",
    "\n",
    "At their core, embeddings are **numerical representations of text**. Instead of storing “1 cup sugar” as raw text, we transform it into a high-dimensional vector — a long list of numbers that capture its meaning. These vectors are designed so that similar pieces of text end up close together in this mathematical space.  \n",
    "\n",
    "For example:  \n",
    "\n",
    "- The chunk “Preheat oven to 350°F” should land close to “Heat oven to 180°C” because both describe the same cooking action.  \n",
    "- “1 cup sugar” and “200 grams sugar” should cluster together, because they refer to the same ingredient (even if units differ).  \n",
    "- “Cake” should end up closer to “muffin” than to “tomato soup.”  \n",
    "\n",
    "In other words, embeddings turn words, sentences, or whole documents into **points in space**, where *distance equals similarity*.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why Do We Need Embeddings for Recipes?\n",
    "\n",
    "Recipes are naturally **semi-structured**: they have titles, lists of ingredients, instructions, and sometimes tables. Without embeddings, searching for a recipe by keyword is brittle — “flourless cake” might not appear in a search for “chocolate dessert.” But with embeddings, we can search by *meaning*.  \n",
    "\n",
    "This opens up some interesting possibilities:  \n",
    "\n",
    "- **Semantic search**: Ask, “Show me recipes with no dairy,” and retrieve relevant chunks, even if the text doesn’t literally use the word *“dairy.”*  \n",
    "- **Ingredient substitution**: Query “egg replacement” and surface recipes that mention “flaxseed egg” or “applesauce.”  \n",
    "- **Contextual retrieval**: If the query is “quick desserts under 30 minutes,” embeddings can help pull together the right mix of instructions, ingredient lists, and prep times.  \n",
    "\n",
    "Embeddings, therefore, become the bridge between our messy human recipe book and a structured, intelligent search experience.  \n",
    "\n",
    "---\n",
    "\n",
    "### How Do We Generate Embeddings?\n",
    "\n",
    "In practice, generating embeddings involves feeding each recipe chunk into a pre-trained embedding model. These models are trained on large amounts of text and are designed to capture linguistic and semantic relationships. For our use case:  \n",
    "\n",
    "1. **Chunking**: Each recipe (or section of a recipe) is broken down into smaller, meaningful chunks.  \n",
    "2. **Embedding**: Each chunk is passed through the embedding model, producing a vector representation.  \n",
    "3. **Storing**: The vectors are saved in a vector database (e.g., FAISS, Pinecone, Weaviate), where they can be efficiently compared.  \n",
    "\n",
    "Now, instead of storing raw text only, we store both the text *and* its embedding.  \n",
    "\n",
    "---\n",
    "\n",
    "### A Concrete Example\n",
    "\n",
    "Suppose we chunked our PDF into the following two snippets:  \n",
    "\n",
    "- *“Step 1: Preheat oven to 350°F (175°C). Grease and flour two 9-inch cake pans.”*  \n",
    "- *“Step 2: In a bowl, whisk together sugar, eggs, and oil until smooth.”*  \n",
    "\n",
    "To the embedding model, these are just text inputs. It outputs something like:  \n",
    "\n",
    "```python\n",
    "[0.032, -0.145, 0.876, ... , 0.217]  # vector for Step 1\n",
    "[0.118, -0.092, 0.934, ... , 0.451]  # vector for Step 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72b2e4",
   "metadata": {},
   "source": [
    "### Local Embedding Models: Pros and Cons\n",
    "\n",
    "| Model                                | Dim. | Pros                                                                 | Cons                                                                 |\n",
    "|--------------------------------------|------|----------------------------------------------------------------------|----------------------------------------------------------------------|\n",
    "| **SentenceTransformers (all-MiniLM-L6-v2)** | 384  | - Very lightweight, runs on CPU/GPU<br>- Fast inference<br>- Good general-purpose performance | - Lower dimensionality may limit nuance<br>- Less accurate on domain-specific data |\n",
    "| **SentenceTransformers (all-mpnet-base-v2)** | 768  | - Strong semantic performance<br>- Widely benchmarked<br>- Still relatively efficient | - Slower than MiniLM<br>- Larger memory footprint |\n",
    "| **intfloat/e5-small / e5-base / e5-large** | 384 / 768 / 1024 | - Optimized for retrieval (query/document embedding)<br>- High accuracy on search/retrieval tasks<br>- Open-source | - Larger variants need more GPU/CPU<br>- Slightly slower than MiniLM for same dimension |\n",
    "| **GTE (gte-small / gte-base / gte-large)** | 384 / 768 / 1024 | - Strong multilingual support<br>- Good for cross-language search<br>- Competitive accuracy | - Larger models require more VRAM<br>- Still evolving community support |\n",
    "\n",
    "---\n",
    "\n",
    "**Quick takeaways**:  \n",
    "- If you want **speed + lightweight**, go with **MiniLM** or **e5-small**.  \n",
    "- For **balanced accuracy and efficiency**, **mpnet-base** or **e5-base** are solid choices.  \n",
    "- If you need **multilingual** support, check out **GTE models**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80797761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "project_root = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "from common.helper import read_pdf, extract_recipes_from_pdf\n",
    "\n",
    "inp_dir = os.path.join(project_root, \"data\", \"chunks\")\n",
    "MODEL_NAME = \"intfloat/e5-base-v2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d5b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 23 chunks\n",
      "Chunk text: Directions Step 1 Preheat oven to 350 degrees F (175 degrees C). Grease and fl our two 9 inch, round, cake pans; cover bottoms with waxed paper. Step 2 In a large bowl, combine fl our, 2 cups sugar, c...\n",
      "Embedding vector (first 10 values): [-0.006904602516442537, 0.001459900289773941, -0.04020014405250549, 0.009997756220400333, 0.057940173894166946, -0.05789573863148689, 0.057525020092725754, 0.01736609824001789, -0.0022118366323411465, -0.017856286838650703]  ...\n"
     ]
    }
   ],
   "source": [
    "# Loads recipe chunks, generates embeddings for one chunk, and prints results.\n",
    "# 1. Suppress warnings for cleaner output.\n",
    "# 2. Initialize the embedding model with normalization.\n",
    "# 3. Load recipe chunks from JSON file and print count.\n",
    "# 4. Generate embedding for the first chunk and print sample text and embedding vector.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=MODEL_NAME, encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "chunks = json.load(open(f\"{inp_dir}/recipe_chunks.json\", \"r\", encoding=\"utf-8\"))\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# embed one chunk for example\n",
    "chunk_text = chunks[0]['content']\n",
    "chunk_embeddings = embeddings.embed_documents([chunk_text])\n",
    "\n",
    "print(f\"Chunk text: {chunk_text[:200]}...\")\n",
    "print(f\"Embedding vector (first 10 values): {chunk_embeddings[0][:10]}  ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
